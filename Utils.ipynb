{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706c6ebd",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- Summary Statistics\n",
    "- Data Cleaning\n",
    "- Dataframe Operations\n",
    "- Preprocessing\n",
    "- EDA\n",
    "  - Univariate Analysis\n",
    "  - Bivariate Analysis\n",
    "- Ml Algos\n",
    "    - Regression\n",
    "    - Classification\n",
    "    - Clustering\n",
    "- Evaluation Metrics\n",
    "- Neural Networks\n",
    "    - Regression\n",
    "    - Classification\n",
    "- Library Imports    \n",
    "- *GPU Support*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68478ab",
   "metadata": {},
   "source": [
    "### Summary statistics\n",
    "- df.head()\n",
    "- df.info()\n",
    "- Numerical column summary\n",
    "```\n",
    "df.describe().transpose()\n",
    "```\n",
    "- Categorical column summary\n",
    "```\n",
    "df.describe(include=['O']).transpose()\n",
    "```\n",
    "- df.shape\n",
    "- Get columns with missing values\n",
    "```\n",
    "missing_value_df = round(df.isnull().sum() / len(df)  * 100,2)\n",
    "missing_value_df[missing_value_df > 0].sort_values(ascending=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e322ba3",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f255a2b",
   "metadata": {},
   "source": [
    "#### 1. Duplicate rows\n",
    "df[df.duplicated()]\n",
    "\n",
    "#### 2. Drop columns where all values are same\n",
    "df.columns[df.nunique() <= 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5461c6",
   "metadata": {},
   "source": [
    "### Dataframe Ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83667f8f",
   "metadata": {},
   "source": [
    "####  1. Drop columns\n",
    "df.drop(columns=column_list)\n",
    "\n",
    "####  2. Get columns whose name starting with\n",
    "```\n",
    "fb_user_cols = [col for col in df.columns if 'fb_user' in col]\n",
    "df[fb_user_cols]\n",
    "```\n",
    "####  3. Categorical columns\n",
    "```\n",
    "# get categorical columns\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "```\n",
    "#### 4. Filter column\n",
    "```\n",
    "df[['count_rech_3g_6', 'arpu_3g_6', 'monthly_3g_6', 'sachet_3g_6']][df.arpu_3g_6.isnull()][:5]\n",
    "```\n",
    "#### 5. Row wise sum \n",
    "```\n",
    "df['churn'] = df[['total_ic_mou_9', 'total_og_mou_9', 'vol_2g_mb_9', 'vol_3g_mb_9']].sum(axis = 1) == 0\n",
    "```\n",
    "#### 6. Column wise sum \n",
    "```\n",
    "df['churn'] = df[['total_ic_mou_9', 'total_og_mou_9', 'vol_2g_mb_9', 'vol_3g_mb_9']].sum(axis = 0) == 0\n",
    "```\n",
    "\n",
    "#### 7. Value Counts %\n",
    "```\n",
    "(df.churn.value_counts() / len(df) * 100).sort_values(ascending=False)\n",
    "```\n",
    "\n",
    "#### 8. Dataframe get columns whose name contains the string\n",
    "```\n",
    "def get_col(df, col_str):\n",
    "    '''\n",
    "    returns column names of df having the stringcol_str\n",
    "    '''\n",
    "    return np.array([col for col in df.columns if col_str in col])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc61bd",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "- Missing Value Percentage\n",
    "```\n",
    "missing_value_df = round(df.isnull().sum() / len(df)  * 100,2)\n",
    "missing_value_df[missing_value_df > 0].sort_values(ascending=False)\n",
    "```\n",
    "- Missing Value Imputation\n",
    "```\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "my_imputer = SimpleImputer(strategy='median')\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns\n",
    "```\n",
    "- Fill null with 0\n",
    "```\n",
    "df[rech_cols] = df[rech_cols].apply(lambda x: x.fillna(0))\n",
    "```\n",
    "- Categorical columns\n",
    "\n",
    "    **ordinal encoding**\n",
    "```\n",
    "def label_encode(val, mapping):\n",
    "    return mapping[val]\n",
    "```\n",
    "```\n",
    "mapping_utilities = {'ELO' : 1, 'NoSeWa' : 2, 'NoSewr': 3, 'AllPub' : 4}\n",
    "df['Utilities'] = df['Utilities'].apply(lambda val :        label_encode(val,mapping_utilities))\n",
    "```\n",
    "\n",
    "    *Same as above usking sklearn*\n",
    "```\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "label_X_train[good_label_cols] = enc.fit_transform(label_X_train[good_label_cols])\n",
    "label_X_valid[good_label_cols] = enc.transform(label_X_valid[good_label_cols])\n",
    "```\n",
    "\n",
    "    *In the case that the validation data contains values that don't appear in the training data, the encoder will throw an error*\n",
    "\n",
    "```\n",
    "# All categorical columns\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Columns that can be safely ordinal encoded\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_valid[col]).issubset(set(X_train[col]))]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)\n",
    "```\n",
    "\n",
    "   **nominal encoding**\n",
    "    \n",
    "```\n",
    "cat_cols = [\"MSZoning\",\"Street\",\"Alley\"]\n",
    "df_cat = df[cat_cols]\n",
    "df_cat_dummies = pd.get_dummies(df_cat, drop_first=True)\n",
    "df = df.drop(cat_cols, axis=1)\n",
    "df = pd.concat([df, df_cat_dummies], axis=1)\n",
    "```\n",
    "\n",
    "*The above is going to have probolems if there are some categories present in train but not in test, so use below*\n",
    "```\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Use as many lines of code as you need!\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_X_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_X_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "OH_X_train.index = X_train.index\n",
    "OH_X_valid.index = X_valid.index\n",
    "\n",
    "num_X_train = X_train.drop(low_cardinality_cols + high_cardinality_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(low_cardinality_cols + high_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_X_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_X_valid], axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac72528",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "#### Univariate analysis\n",
    "\n",
    "- Plots - distplot for numerical & countplot for categorical\n",
    "```\n",
    "def uni(col):\n",
    "    '''\n",
    "        distplot for numerical\n",
    "        countplot for categorical\n",
    "    '''\n",
    "    if 'int' in str(col.dtype):\n",
    "        sns.distplot(col)\n",
    "    elif 'int' in str(col.dtype):\n",
    "        sns.countplot(col)\n",
    "```\n",
    "- Sub plots\n",
    "```\n",
    "plt.figure(figsize=(16, 12))\n",
    "uni_cols = list(get_col(high_value_cust_df, 'net'))\n",
    "for col in uni_cols:\n",
    "    plt.subplot(3,3, uni_cols.index(col) + 1)\n",
    "    uni(high_value_cust_df[col])\n",
    "```\n",
    "\n",
    "#### Bivariate analysis\n",
    "- Categorical vs numerical relationship\n",
    "```\n",
    "sns.boxplot(data=capped_df, x='churn', y='aon')\n",
    "```\n",
    "- Correlations\n",
    "```\n",
    "df.corr()\n",
    "sns.heatmap(df.corr(), annot = True, cmap=\"YlGnBu\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edeabc8",
   "metadata": {},
   "source": [
    "### Library Imports\n",
    "- Pandas and numpy\n",
    "    ```\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    ```\n",
    "- Plots\n",
    "    ```\n",
    "    import numpy as np\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    ```\n",
    "- Scaling\n",
    "    ```\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    ```\n",
    "- Split\n",
    "    ```\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    ```\n",
    "- Linear Regression\n",
    "    ```\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    ```\n",
    "- Logistic Regression\n",
    "    ```\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    ```\n",
    "- Decision Trees\n",
    "- RandomForestRegressor\n",
    "    ```\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    ```\n",
    "- Random Forest Classifier\n",
    "    ```\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    ```\n",
    "- PCA\n",
    "    ```\n",
    "    from sklearn.decomposition import PCA\n",
    "    ```\n",
    "- Clustering\n",
    "- Cross Validation\n",
    "    ```\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    ```\n",
    "- Evaluation Metrics\n",
    "    - Regression\n",
    "        ```\n",
    "        from sklearn import metrics\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        ```\n",
    "    - Classification\n",
    "        ```\n",
    "        from sklearn.metrics import classification_report\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa233648",
   "metadata": {},
   "source": [
    "### ML Algos\n",
    "\n",
    "#### 1. Regression\n",
    "- RandomForestRegressor\n",
    "    ```\n",
    "    RandomForestRegressor(random_state=42, n_jobs=-1, max_depth=5, min_samples_leaf=10,\n",
    "                          n_estimators=100)\n",
    "    ```\n",
    "#### 2. Classification\n",
    "#### 3. Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9397f0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83092eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df6daa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9cdd2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6289567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([3,1,5,7,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b256a6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10232f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
